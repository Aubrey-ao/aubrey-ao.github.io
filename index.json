[{"authors":null,"categories":null,"content":"I am a Ph.D student at Peking University, advised by Prof. Libin Liu. I received my B.S. degree in electronic engineering from Tsinghua University in 2020.\nRecently, my interests include:\nInteractive Humanoid Agent: e.g., \u0026ldquo;Body of Her\u0026rdquo; blog: a human-centric entry point for interactive world simulators. Human Motion Synthesis: e.g., co-speech gesture synthesis. Long Story Script-to-Video Generation: I joined a startup team from 2019 to 2021 and helped develop a language-assisted animation creation product that enables users (e.g., Tiktokers and kids) to effortlessly create simple animations by specifying natural language-described story scripts. You can view some demos here. Collaborators:\nZeyi Zhang Baoquan Chen Qingzhe Gao Yuke Lou Heyuan Yao Zhenhua Song Yuyang Zhou Talks:\nGAMES Webinar (20230414)\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Ph.D student at Peking University, advised by Prof. Libin Liu. I received my B.S. degree in electronic engineering from Tsinghua University in 2020.\nRecently, my interests include:","tags":null,"title":"Tenglong Ao 敖腾隆","type":"authors"},{"authors":["Tenglong Ao"],"categories":null,"content":"","date":1723017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723017600,"objectID":"8c4ef5699dc8d13e719c8cef7b563b92","permalink":"/publication/bodyofher/","publishdate":"2024-08-07T08:00:00Z","relpermalink":"/publication/bodyofher/","section":"publication","summary":"A real-time, duplex, interactive end-to-end network capable of modeling realistic agent behaviors, including speech, full-body movements for talking, responding, idling, and manipulation.","tags":[],"title":"Body of Her: A Preliminary Study on End-to-End Humanoid Agent","type":"publication"},{"authors":["Heyuan Yao","Zhenhua Song","Yuyang Zhou","Tenglong Ao","Baoquan Chen","Libin Liu"],"categories":null,"content":"","date":171576e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":171576e4,"objectID":"0baf6239da6f4b02038795f816e93a79","permalink":"/publication/moconvq/","publishdate":"2024-05-15T08:00:00Z","relpermalink":"/publication/moconvq/","section":"publication","summary":"We present a novel unified framework for physics-based motion control leveraging scalable discrete representations. By harnessing a large dataset of tens of hours of motions, our method learns a rich motion representation, allowing various downstream tasks such as physics-based pose estimation, interactive motion control, text2motion generation, and, more interestingly, seamless integration with large language models (LLMs).","tags":[],"title":"MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete Representations","type":"publication"},{"authors":["Zeyi Zhang","Tenglong Ao","Yuyao Zhang","Qingzhe Gao","Chuan Lin","Baoquan Chen","Libin Liu"],"categories":null,"content":"","date":1715731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715731200,"objectID":"478d7ac7e8cf47d4505ed3ed4f77e36e","permalink":"/publication/semantic-gesticulator/","publishdate":"2024-05-15T00:00:00Z","relpermalink":"/publication/semantic-gesticulator/","section":"publication","summary":"We introduce Semantic Gesticulator, a novel framework designed to synthesize realistic co-speech gestures with strong semantic correspondence. Semantic Gesticulator fine-tunes an LLM to retrieve suitable semantic gesture candidates from a motion library. Combined with a novel, GPT-style generative model, the generated gesture motions demonstrate strong rhythmic coherence and semantic appropriateness.","tags":[],"title":"Semantic Gesticulator: Semantics-aware Co-speech Gesture Synthesis","type":"publication"},{"authors":["Tenglong Ao","Zeyi Zhang","Libin Liu"],"categories":null,"content":"","date":1679961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679961600,"objectID":"3c5667ee6ef32cea891b61938bc6b296","permalink":"/publication/gesturediffuclip/","publishdate":"2023-03-28T00:00:00Z","relpermalink":"/publication/gesturediffuclip/","section":"publication","summary":"We introduce GestureDiffuCLIP, a CLIP-guided, co-speech gesture synthesis system that creates stylized gestures in harmony with speech semantics and rhythm using arbitrary style prompts. Our highly adaptable system supports style prompts in the form of short texts, motion sequences, or video clips and provides body part-specific style control.","tags":[],"title":"GestureDiffuCLIP: Gesture Diffusion Model with CLIP Latents","type":"publication"},{"authors":["Tenglong Ao","Qingzhe Gao","Yuke Lou","Baoquan Chen","Libin Liu"],"categories":null,"content":"","date":1669766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669766400,"objectID":"09ce54fe82d365347f0fba9f95d73995","permalink":"/publication/rhythmic-gesticulator/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/publication/rhythmic-gesticulator/","section":"publication","summary":"We present a co-speech gesture synthesis system that achieves convincing results both on the rhythm and semantics.","tags":[],"title":"Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings","type":"publication"},{"authors":null,"categories":null,"content":" Figure 1. Synthesis Pipeline As shown in Figure 1, we develop an automated production tool that can efficiently generate animations from natural language-described story scripts. The synthesis pipeline contains two stages:\nUtilizing our animation model, which is a complex system that integrates NLP analysis and a Unity-based graphics engine, to generate an animation clip from a story script. Making further adjustments to the animation using an interactive editing tool, such as CapCut for TikTok. Below are several animation demos created by our system from story scripts written in Chinese:\nVideo 1. Animation generated from a story script about Naming. Video 2. Animation generated from a story script about Rent Collection. Video 3. Animation generated from a story script about the Chairman's Inspection. Video 4. Animation generated from a story script about Peppa Pig. Video 5. Animation generated from a description of a scene about a Castle Dinner. Video 6. Animation generated from a story script about Ultraman. Besides, we generated more animation videos using an earlier version of our product and shared them on Douyin (ID: heidongdonghua) \u0026ndash; the Chinese TikTok, on an irregular basis.\n","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"4ef697851f50cf315aaf8487a8ac1c7b","permalink":"/project/story2animation/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/project/story2animation/","section":"project","summary":"Figure 1. Synthesis Pipeline As shown in Figure 1, we develop an automated production tool that can efficiently generate animations from natural language-described story scripts. The synthesis pipeline contains two stages:","tags":null,"title":"Animation Synthesis from Story Scripts","type":"project"},{"authors":["Nice Colleagues","Tenglong Ao"],"categories":null,"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"24f3b0c161976c5913425faaf283088b","permalink":"/publication/story2animation/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/publication/story2animation/","section":"publication","summary":"We develop a language-assisted animation creation product that enables users (e.g., Tiktokers and kids) to effortlessly create simple animations by specifying natural language-described story scripts.","tags":[],"title":"Animation Synthesis from Story Scripts","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"}]